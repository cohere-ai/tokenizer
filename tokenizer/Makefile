# Makefile for python interface for package tokenizer.
# File is generated by gopy. Do not edit.
# gopy build -output=tokenizer -vm=/bin/python3 /home/callum_cohere_ai/tokenizer

GOCMD=go
GOBUILD=$(GOCMD) build -mod=mod
GOIMPORTS=goimports
PYTHON=/bin/python3
LIBEXT=.so

# get the CC and flags used to build python:
GCC = $(shell $(GOCMD) env CC)
CFLAGS = -I/usr/include/python3.8
LDFLAGS = -L/usr/lib -lpython3.8 -lcrypt -lpthread -ldl  -lutil -lm -lm

all: gen build

gen:
	gopy gen -no-make -vm=/bin/python3 /home/callum_cohere_ai/tokenizer

build:
	# build target builds the generated files -- this is what gopy build does..
	# this will otherwise be built during go build and may be out of date
	- rm tokenizer.c
	# goimports is needed to ensure that the imports list is valid
	$(GOIMPORTS) -w tokenizer.go
	# generate tokenizer_go$(LIBEXT) from tokenizer.go -- the cgo wrappers to go functions
	$(GOBUILD) -buildmode=c-shared -o tokenizer_go$(LIBEXT) tokenizer.go
	# use pybindgen to build the tokenizer.c file which are the CPython wrappers to cgo wrappers..
	# note: pip install pybindgen to get pybindgen if this fails
	$(PYTHON) build.py
	# build the _tokenizer$(LIBEXT) library that contains the cgo and CPython wrappers
	# generated tokenizer.py python wrapper imports this c-code package
	
	$(GCC) tokenizer.c  tokenizer_go$(LIBEXT) -o _tokenizer$(LIBEXT) $(CFLAGS) $(LDFLAGS) -fPIC --shared -w
	



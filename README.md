# tokenizers

Cohere's `tokenizers` library provides an interface to encode and decode text given a computed vocabulary, and includes pre-computed tokenizers that are used to train Cohere's models. 

We plan on eventually also open sourcing tools to create new tokenizers. 

## Example
